import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.neighbors import KNeighborsRegressor
from sklearn.svm import SVR
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error, r2_score, classification_report
import matplotlib.pyplot as plt

# 1. Carga y limpieza
data = pd.read_csv('DatosViviendaPeru.csv', encoding='latin1', sep=';', on_bad_lines='skip')

# Normalizar nombres columnas
data.columns = data.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('ó','o').str.replace('ú','u').str.replace('ñ','n')

cols_num_potenciales = [
    'precio_en_soles_corrientes',
    'precio_en_dolares_corrientes',
    'precio_en_soles_constantes_de_2009',
    'superficie',
    'numero_de_habitaciones',
    'numero_de_banos',
    'numero_de_garajes',
    'piso_de_ubicacion',
    'anos_de_antiguedad',
    'ipc',
    'tipo_de_cambio',
    'trimestre',
    'ano'
]

for col in cols_num_potenciales:
    if col in data.columns:
        data[col] = data[col].astype(str).str.replace(' ', '').str.replace(',', '.')
        data[col] = pd.to_numeric(data[col], errors='coerce')

target_col = 'precio_en_soles_corrientes'
data = data.dropna(subset=[target_col])

X = data.drop(columns=[target_col])
y = data[target_col]

# Codificar variable categórica
cat_col = 'distrito'
le = LabelEncoder()
X[cat_col] = le.fit_transform(X[cat_col].astype(str))

num_cols = X.select_dtypes(include=[np.number]).columns.tolist()
for col in num_cols:
    X[col].fillna(X[col].mean(), inplace=True)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train[num_cols] = scaler.fit_transform(X_train[num_cols])
X_test[num_cols] = scaler.transform(X_test[num_cols])

# Optimización KNN con GridSearchCV
param_grid_knn = {'n_neighbors': range(1, 21), 'weights': ['uniform', 'distance']}
grid_knn = GridSearchCV(KNeighborsRegressor(), param_grid_knn, cv=5, scoring='neg_mean_squared_error')
grid_knn.fit(X_train, y_train)
best_knn = grid_knn.best_estimator_

print("Mejores parámetros KNN:", grid_knn.best_params_)
print("Mejor score CV (neg MSE):", grid_knn.best_score_)

# Modelos a evaluar (incluyendo el KNN optimizado)
models = {
    'Regresión Lineal': LinearRegression(),
    'KNN Regressor Optimizado': best_knn,
    'SVR (Kernel RBF)': SVR(kernel='rbf'),
    'Árbol de Regresión': DecisionTreeRegressor(random_state=42)
}

results = {}
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    r2 = r2_score(y_test, y_pred)
    results[name] = {'RMSE': rmse, 'R2': r2, 'y_pred': y_pred}
    print(f"{name}: RMSE = {rmse:.2f}, R2 = {r2:.2f}")

print("\n=== Reporte detallado regresión ===\n")
for name, metric in results.items():
    print(f"Modelo: {name}")
    print(f"  - RMSE: {metric['RMSE']:.4f}")
    print(f"  - R²: {metric['R2']:.4f}")
    print("-" * 40)

# Definir bins ampliados para evitar NaN en categorías
bins = [y.min() - 1, 100000, 200000, 300000, 400000, y.max() + 1]
labels = [0, 1, 2, 3, 4]

print("\n=== Reporte tipo clasificación por rangos de precio ===\n")

for name, metric in results.items():
    # Limpieza NaN en predicciones
    y_pred_clean = np.nan_to_num(metric['y_pred'], nan=np.nanmin(metric['y_pred']))

    y_true_cat = pd.cut(y_test, bins=bins, labels=labels, include_lowest=True)
    y_pred_cat = pd.cut(y_pred_clean, bins=bins, labels=labels, include_lowest=True)

    # Quitar NaN resultantes de pd.cut (si hay)
    mask = y_true_cat.notna() & y_pred_cat.notna()
    y_true_cat_clean = y_true_cat[mask]
    y_pred_cat_clean = y_pred_cat[mask]

    print(f"Reporte {name}:")
    print(classification_report(y_true_cat_clean, y_pred_cat_clean, zero_division=0))
    print("-" * 60)

# Gráficos métricas
df_metrics = pd.DataFrame({
    'Modelo': list(results.keys()),
    'RMSE': [v['RMSE'] for v in results.values()],
    'R2': [v['R2'] for v in results.values()]
})

fig, ax1 = plt.subplots(figsize=(10,6))
df_metrics.set_index('Modelo')['RMSE'].plot(kind='bar', ax=ax1, color='orange', position=0, width=0.4)
ax1.set_ylabel('RMSE')
ax1.set_title('Comparación de RMSE y R2 de modelos')
ax1.set_xticklabels(df_metrics['Modelo'], rotation=45)

ax2 = ax1.twinx()
df_metrics.set_index('Modelo')['R2'].plot(kind='bar', ax=ax2, color='skyblue', position=1, width=0.4)
ax2.set_ylabel('R2 Score')

ax1.legend(['RMSE'])
ax2.legend(['R2'], loc='upper right')
plt.show()

# Gráficos predicción vs real
for name, vals in results.items():
    plt.figure(figsize=(6,6))
    plt.scatter(y_test, vals['y_pred'], alpha=0.5)
    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
    plt.xlabel('Valores reales')
    plt.ylabel('Valores predichos')
    plt.title(f'Predicción vs Real: {name}')
    plt.grid(True)
    plt.show()
